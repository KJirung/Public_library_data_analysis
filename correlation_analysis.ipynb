{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import scipy.stats as stats\n",
    "from itertools import combinations\n",
    "\n",
    "# 소수를 e로 표현하지 않도록 하기\n",
    "pd.options.display.float_format = \"{:.5f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_2007 = pd.read_csv(\"final_data/lib_2007.csv\")\n",
    "lib_2008 = pd.read_csv(\"final_data/lib_2008.csv\")\n",
    "lib_2009 = pd.read_csv(\"final_data/lib_2009.csv\")\n",
    "lib_2010 = pd.read_csv(\"final_data/lib_2010.csv\")\n",
    "lib_2011 = pd.read_csv(\"final_data/lib_2011.csv\")\n",
    "lib_2012 = pd.read_csv(\"final_data/lib_2012.csv\")\n",
    "lib_2013 = pd.read_csv(\"final_data/lib_2013.csv\")\n",
    "lib_2014 = pd.read_csv(\"final_data/lib_2014.csv\")\n",
    "lib_2015 = pd.read_csv(\"final_data/lib_2015.csv\")\n",
    "lib_2016 = pd.read_csv(\"final_data/lib_2016.csv\")\n",
    "lib_2017 = pd.read_csv(\"final_data/lib_2017.csv\")\n",
    "lib_2018 = pd.read_csv(\"final_data/lib_2018.csv\")\n",
    "lib_2019 = pd.read_csv(\"final_data/lib_2019.csv\")\n",
    "lib_2020 = pd.read_csv(\"final_data/lib_2020.csv\")\n",
    "lib_2021 = pd.read_csv(\"final_data/lib_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lib = pd.concat([lib_2007,lib_2008,lib_2009,lib_2010,lib_2011,lib_2012,lib_2013,lib_2014,lib_2015])\n",
    "valid_lib = pd.concat([lib_2016,lib_2017,lib_2018])\n",
    "test_lib = pd.concat([lib_2019,lib_2020,lib_2021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set의 데이터 수 : 6808\n",
      "valid set의 데이터 수 : 2848\n",
      "test set의 데이터 수 : 3483\n"
     ]
    }
   ],
   "source": [
    "# train, test set의 데이터 수 구하기\n",
    "print(f\"train set의 데이터 수 : {len(train_lib)}\")\n",
    "print(f\"valid set의 데이터 수 : {len(valid_lib)}\")\n",
    "print(f\"test set의 데이터 수 : {len(test_lib)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이상치 제거 후 train set의 데이터 수 : 4014\n",
      "이상치 제거 후 valid set의 데이터 수 : 2398\n",
      "이상치 제거 후 test set의 데이터 수 : 3004\n"
     ]
    }
   ],
   "source": [
    "# 사분위수를 활용하여 비율 충족도의 이상치 행 제거하기\n",
    "def del_outlier(df, col):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1 \n",
    "    boundary = 1.5 * iqr \n",
    "\n",
    "    upper_index = df[df[col] > q3 + boundary].index\n",
    "    lower_index = df[df[col] < q1 - boundary].index \n",
    "\n",
    "    df.drop(upper_index, inplace = True)\n",
    "    df.drop(lower_index, inplace = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "del_outlier(train_lib, \"Future_fullfillment\")\n",
    "del_outlier(valid_lib, \"Future_fullfillment\")\n",
    "del_outlier(test_lib, \"Future_fullfillment\") \n",
    "\n",
    "# 이상치 제거 후 train, test set의 데이터 수 구하기\n",
    "print(f\"이상치 제거 후 train set의 데이터 수 : {len(train_lib)}\")\n",
    "print(f\"이상치 제거 후 valid set의 데이터 수 : {len(valid_lib)}\")\n",
    "print(f\"이상치 제거 후 test set의 데이터 수 : {len(test_lib)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set과 test set 내에 있는 변수들에 대해 로그 변환하기\n",
    "\n",
    "for col in train_lib.columns[:-1]:\n",
    "    train_lib[col] = np.log1p(train_lib[col])\n",
    "    \n",
    "for col in valid_lib.columns[:-1]:\n",
    "    valid_lib[col] = np.log1p(valid_lib[col])\n",
    "\n",
    "for col in test_lib.columns[:-1]:\n",
    "    test_lib[col] = np.log1p(test_lib[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, Y_train 구성하기\n",
    "X_train = train_lib.loc[:, (train_lib.columns != \"Future_fullfillment\")]\n",
    "Y_train = train_lib[\"Future_fullfillment\"]\n",
    "\n",
    "# X_valid, Y_valid 구성하기\n",
    "X_valid = valid_lib.loc[:, (valid_lib.columns != \"Future_fullfillment\")]\n",
    "Y_valid = valid_lib[\"Future_fullfillment\"]\n",
    "\n",
    "# X_test, Y_test 구성하기\n",
    "X_test = test_lib.loc[:, (test_lib.columns != \"Future_fullfillment\")]\n",
    "Y_test = test_lib[\"Future_fullfillment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비율충족도가 0일 경우 해당 값을 0.000001로 변환하기\n",
    "Y_train[Y_train == 0] = 0.000001\n",
    "Y_valid[Y_valid == 0] = 0.000001\n",
    "Y_test[Y_test == 0] = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['Feature1', 'Feature2', 'Pearson_Corr', 'Pearson_p-value', 'Spearman_Corr', 'Spearman_p-value', 'Kendall_Corr', 'Kendall_p-value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['dom_books','for_books','local_mat','nonbook_mat','elec_mat','serials','ann_growth','ann_weeding', 'lib_site_area', 'lib_build_area', 'total_seats', 'user_comps', 'self_srv_machines', 'full_time', 'part_time', 'support_staff', 'total_budget', 'acq_budget', 'open_days', 'avg_week_hours', 'reg_members', 'lib_visitors', 'service_recip', 'borrowers', 'loans', 'interlib_loans', 'info_serv_requests', 'web_access', 'user_ed_sessions', 'user_ed_partic', 'prog_sessions', 'prog_partic', 'disab_mat', 'vuln_group_budget', 'total_settlement', 'acq_budget_settlement'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 조합 생성\n",
    "feature_pairs = list(combinations(features, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA 및 상관관계 분석\n",
    "result_list = []\n",
    "for X1, X2 in feature_pairs:\n",
    "    X1_data = X_test[[X1]]\n",
    "    X2_data = X_test[[X2]]\n",
    "    \n",
    "    cca = CCA(scale=False, n_components=1)\n",
    "    cca.fit(X1_data, X2_data)\n",
    "    X1_c, X2_c = cca.transform(X1_data, X2_data)\n",
    "    \n",
    "    corr_coefficient, p_value = np.corrcoef(X1_c[:, 0], X2_c[:, 0])[0, 1], linregress(X1_c[:, 0], X2_c[:, 0]).pvalue\n",
    "    \n",
    "    rho, p_val = stats.pearsonr(X1_c[:, 0], X2_c[:, 0])\n",
    "    rho_spearman, p_val_spearman = stats.spearmanr(X1_c[:, 0], X2_c[:, 0])\n",
    "    rho_kendall, p_val_kendall = stats.kendalltau(X1_c[:, 0], X2_c[:, 0])\n",
    "    \n",
    "    result_list.append([X1, X2, rho, p_val, rho_spearman, p_val_spearman, rho_kendall, p_val_kendall])\n",
    "\n",
    "result_df = pd.DataFrame(result_list, columns=['Feature1', 'Feature2', 'Pearson_Corr', 'Pearson_p-value', 'Spearman_Corr', 'Spearman_p-value', 'Kendall_Corr', 'Kendall_p-value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 저장\n",
    "result_df.to_csv('cca_results/test_cca.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jw_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
