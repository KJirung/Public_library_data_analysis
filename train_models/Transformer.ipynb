{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# 소수를 e로 표현하지 않도록 하기\n",
    "pd.options.display.float_format = \"{:.5f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_2007 = pd.read_csv(\"../final_data/lib_2007.csv\", index_col=0)\n",
    "lib_2008 = pd.read_csv(\"../final_data/lib_2008.csv\", index_col=0)\n",
    "lib_2009 = pd.read_csv(\"../final_data/lib_2009.csv\", index_col=0)\n",
    "lib_2010 = pd.read_csv(\"../final_data/lib_2010.csv\", index_col=0)\n",
    "lib_2011 = pd.read_csv(\"../final_data/lib_2011.csv\", index_col=0)\n",
    "lib_2012 = pd.read_csv(\"../final_data/lib_2012.csv\", index_col=0)\n",
    "lib_2013 = pd.read_csv(\"../final_data/lib_2013.csv\", index_col=0)\n",
    "lib_2014 = pd.read_csv(\"../final_data/lib_2014.csv\", index_col=0)\n",
    "lib_2015 = pd.read_csv(\"../final_data/lib_2015.csv\", index_col=0)\n",
    "lib_2016 = pd.read_csv(\"../final_data/lib_2016.csv\", index_col=0)\n",
    "lib_2017 = pd.read_csv(\"../final_data/lib_2017.csv\", index_col=0)\n",
    "lib_2018 = pd.read_csv(\"../final_data/lib_2018.csv\", index_col=0)\n",
    "lib_2019 = pd.read_csv(\"../final_data/lib_2019.csv\", index_col=0)\n",
    "lib_2020 = pd.read_csv(\"../final_data/lib_2020.csv\", index_col=0)\n",
    "lib_2021 = pd.read_csv(\"../final_data/lib_2021.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lib = pd.concat([lib_2007,lib_2008,lib_2009,lib_2010,lib_2011,lib_2012,lib_2013,lib_2014,lib_2015, lib_2016, lib_2017])\n",
    "valid_lib = pd.concat([lib_2018, lib_2019])\n",
    "test_lib = pd.concat([lib_2020,lib_2021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set의 데이터 수 : 9026\n",
      "valid set의 데이터 수 : 2222\n",
      "test set의 데이터 수 : 2370\n"
     ]
    }
   ],
   "source": [
    "# train, test set의 데이터 수 구하기\n",
    "print(f\"train set의 데이터 수 : {len(train_lib)}\")\n",
    "print(f\"valid set의 데이터 수 : {len(valid_lib)}\")\n",
    "print(f\"test set의 데이터 수 : {len(test_lib)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이상치 제거 후 train set의 데이터 수 : 8184\n",
      "이상치 제거 후 valid set의 데이터 수 : 2178\n",
      "이상치 제거 후 test set의 데이터 수 : 2310\n"
     ]
    }
   ],
   "source": [
    "# 사분위수를 활용하여 비율 충족도의 이상치 행 제거하기\n",
    "def del_outlier(df, col):\n",
    "    q1 = df[col].quantile(0.10)\n",
    "    q3 = df[col].quantile(0.90)\n",
    "    iqr = q3 - q1 \n",
    "    boundary = 1.5 * iqr \n",
    "\n",
    "    upper_index = df[df[col] > q3 + boundary].index\n",
    "    lower_index = df[df[col] < q1 - boundary].index \n",
    "\n",
    "    df.drop(upper_index, inplace = True)\n",
    "    df.drop(lower_index, inplace = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "del_outlier(train_lib, \"future_acq_budget_settlement\")\n",
    "del_outlier(valid_lib, \"future_acq_budget_settlement\")\n",
    "del_outlier(test_lib, \"future_acq_budget_settlement\") \n",
    "\n",
    "# 이상치 제거 후 train, test set의 데이터 수 구하기\n",
    "print(f\"이상치 제거 후 train set의 데이터 수 : {len(train_lib)}\")\n",
    "print(f\"이상치 제거 후 valid set의 데이터 수 : {len(valid_lib)}\")\n",
    "print(f\"이상치 제거 후 test set의 데이터 수 : {len(test_lib)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Min-Max Scaler 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 모든 변수에 대해 Min-Max Scaling 적용\n",
    "# 스케일러를 학습 데이터에 대해 fit\n",
    "scaler.fit(train_lib.drop(columns=[\"future_acq_budget_settlement\"]))\n",
    "\n",
    "# 학습 데이터에 대해 변환\n",
    "train_lib_scaled = pd.DataFrame(scaler.transform(train_lib.drop(columns=[\"future_acq_budget_settlement\"])), \n",
    "                                columns=train_lib.columns[:-1])\n",
    "\n",
    "# 타겟 변수에 대해 스케일링 적용\n",
    "scaler_y = MinMaxScaler()\n",
    "train_y_scaled = scaler_y.fit_transform(train_lib[['future_acq_budget_settlement']])\n",
    "\n",
    "# 학습 데이터에 스케일된 타겟 변수 추가\n",
    "train_lib_scaled['future_acq_budget_settlement_scaled'] = train_y_scaled\n",
    "\n",
    "# 검증 데이터에 대해 변환\n",
    "valid_lib_scaled = pd.DataFrame(scaler.transform(valid_lib.drop(columns=[\"future_acq_budget_settlement\"])), \n",
    "                                columns=train_lib.columns[:-1])\n",
    "valid_y_scaled = scaler_y.transform(valid_lib[['future_acq_budget_settlement']])\n",
    "valid_lib_scaled['future_acq_budget_settlement_scaled'] = valid_y_scaled\n",
    "\n",
    "# 테스트 데이터에 대해 변환\n",
    "test_lib_scaled = pd.DataFrame(scaler.transform(test_lib.drop(columns=[\"future_acq_budget_settlement\"])), \n",
    "                               columns=train_lib.columns[:-1])\n",
    "test_y_scaled = scaler_y.transform(test_lib[['future_acq_budget_settlement']])\n",
    "test_lib_scaled['future_acq_budget_settlement_scaled'] = test_y_scaled\n",
    "\n",
    "# X_train, Y_train 구성하기 (스케일된 타겟 사용)\n",
    "X_train = train_lib_scaled.drop(columns=[\"future_acq_budget_settlement_scaled\"])\n",
    "Y_train = train_lib_scaled[\"future_acq_budget_settlement_scaled\"]\n",
    "\n",
    "# X_valid, Y_valid 구성하기 (스케일된 타겟 사용)\n",
    "X_valid = valid_lib_scaled.drop(columns=[\"future_acq_budget_settlement_scaled\"])\n",
    "Y_valid = valid_lib_scaled[\"future_acq_budget_settlement_scaled\"]\n",
    "\n",
    "# X_test, Y_test 구성하기 (스케일된 타겟 사용)\n",
    "X_test = test_lib_scaled.drop(columns=[\"future_acq_budget_settlement_scaled\"])\n",
    "Y_test = test_lib_scaled[\"future_acq_budget_settlement_scaled\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = [\"prog_sessions\",\t\"local_mat\", \"prog_partic\", \"service_recip\", \"self_srv_machines\", \"interlib_loans\", \n",
    "#                    \"reg_members\", \"borrowers\", \"user_ed_partic\", \"web_access\", \"open_days\", \n",
    "#                    \"avg_week_hours\", \"disab_mat\", \"ann_weeding\", \"support_staff\", \"info_serv_requests\"]\n",
    "\n",
    "# X_train.drop(columns=columns_to_drop, inplace=True)\n",
    "# X_valid.drop(columns=columns_to_drop, inplace=True)\n",
    "# X_test.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘파이로 변환\n",
    "X_train_np = X_train.to_numpy()\n",
    "X_valid_np = X_valid.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n",
    "\n",
    "# 데이터 형태 맞추기\n",
    "X_train_reshaped = X_train_np.reshape((X_train_np.shape[0], X_train_np.shape[1], 1))\n",
    "X_valid_reshaped = X_valid_np.reshape((X_valid_np.shape[0], X_valid_np.shape[1], 1))\n",
    "X_test_reshaped = X_test_np.reshape((X_test_np.shape[0], X_test_np.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 14:05:49.727996: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-15 14:05:49.811005: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-15 14:05:49.811064: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-15 14:05:49.811076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-15 14:05:49.827674: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/root/anaconda3/envs/jw_tensorflow/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "inputs=keras.layers.Input(shape=(36,1))\n",
    "n_classes=1\n",
    "# Transformer 모델에 들어가는 encoder 첫번째\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    print(x)\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "    x1 = keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x2 = tfa.layers.InstanceNormalization()(x)\n",
    "    x = (0.7 * x1) + (0.3 * x2)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"LeakyReLU\")(res)\n",
    "    x1 = keras.layers.Dropout(dropout)(x)\n",
    "    x = keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x1 = keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x2 = tfa.layers.InstanceNormalization()(x)\n",
    "    x = (0.7 * x1) + (0.3 * x2)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "# Transformer 모델에 들어가는 encoder 두번째\n",
    "def transformer_encoder2(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "    x1 = keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x2 = tfa.layers.InstanceNormalization()(x)\n",
    "    x = (0.7 * x1) + (0.3 * x2)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"LeakyReLU\")(res)\n",
    "    x1 = keras.layers.Dropout(dropout)(x)\n",
    "    x = keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x1 = keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x2 = tfa.layers.InstanceNormalization()(x)\n",
    "    x = (0.7 * x1) + (0.3 * x2)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "# Transformer 모델 설계 부분\n",
    "def build_model(\n",
    "        input_shape,\n",
    "        head_size,\n",
    "        num_heads,\n",
    "        ff_dim,\n",
    "        num_transformer_blocks,\n",
    "        mlp_units,\n",
    "        dropout=0,\n",
    "        mlp_dropout=0,\n",
    "):\n",
    "    print(head_size)\n",
    "    print(num_heads)\n",
    "    print(ff_dim)\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x1 = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "    print(x)\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x2 = transformer_encoder2(x, head_size, num_heads, ff_dim, dropout)\n",
    "    print(x2)\n",
    "    x = (0.5 * x1) + (0.5 * x2)\n",
    "    x = keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = keras.layers.Dense(dim, activation=\"LeakyReLU\")(x)\n",
    "        x = keras.layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = keras.layers.Dense(n_classes)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 14:06:00.519444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name=None), name='multi_head_attention/attention_output/add:0', description=\"created by layer 'multi_head_attention'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name=None), name='multi_head_attention_1/attention_output/add:0', description=\"created by layer 'multi_head_attention_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name=None), name='tf.__operators__.add_15/Add:0', description=\"created by layer 'tf.__operators__.add_15'\")\n"
     ]
    }
   ],
   "source": [
    "input_shape = (36,1)\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=2,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-15 14:06:17.753778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-09-15 14:06:18.629537: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90a94f0220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-15 14:06:18.629591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-09-15 14:06:18.639116: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-15 14:06:18.981797: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 33s 25ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 6s 24ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 6s 24ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 13/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 14/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 15/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 16/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 17/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 18/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0236 - val_mse: 0.0236\n",
      "Epoch 19/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 20/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 21/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 22/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 23/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 24/50\n",
      "256/256 [==============================] - 6s 25ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 25/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 26/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 27/50\n",
      "256/256 [==============================] - 6s 24ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 28/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 29/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 30/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 31/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 32/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 33/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 34/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 35/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 36/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 37/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 38/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 39/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 40/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 41/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 42/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 43/50\n",
      "256/256 [==============================] - 6s 24ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 44/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 45/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 46/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 47/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 48/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 49/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 50/50\n",
      "256/256 [==============================] - 6s 24ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0185 - val_mse: 0.0185\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# 모델 컴파일\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics='mse') \n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train_reshaped, Y_train, epochs=50, batch_size=32, validation_data=(X_valid_reshaped, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 3s 7ms/step\n",
      "MSE: 0.013523926958441734\n",
      "RMSE: 0.11629241704940796\n",
      "MAE: 0.0830891877412796\n",
      "SMAPE: 54.6923261994693\n",
      "R²: 0.48122261342888906\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_train_reshaped)\n",
    "\n",
    "# y_pred와 Y_train를 1차원으로 변환\n",
    "y_pred = y_pred.flatten()\n",
    "Y_train = Y_train.to_numpy().flatten()\n",
    "\n",
    "# MSE\n",
    "mse = MeanSquaredError()\n",
    "mse.update_state(Y_train, y_pred)\n",
    "mse_result = mse.result().numpy()\n",
    "\n",
    "# RMSE\n",
    "rmse_result = np.sqrt(mse_result)\n",
    "\n",
    "# MAE\n",
    "mae = MeanAbsoluteError()\n",
    "mae.update_state(Y_train, y_pred)\n",
    "mae_result = mae.result().numpy()\n",
    "\n",
    "# SMAPE (Symmetric Mean Absolute Percentage Error)\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
    "\n",
    "smape_result = smape(Y_train, y_pred)\n",
    "\n",
    "# R² (R Squared)\n",
    "r2_result = r2_score(Y_train, y_pred)\n",
    "\n",
    "print(f'MSE: {mse_result}')\n",
    "print(f'RMSE: {rmse_result}')\n",
    "print(f'MAE: {mae_result}')\n",
    "print(f'SMAPE: {smape_result}')\n",
    "print(f'R²: {r2_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 9ms/step\n",
      "MSE: 0.01852799579501152\n",
      "RMSE: 0.1361175775527954\n",
      "MAE: 0.09319751709699631\n",
      "SMAPE: 53.72654881969792\n",
      "R²: 0.32727214644552227\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_valid_reshaped)\n",
    "\n",
    "# y_pred와 Y_valid를 1차원으로 변환\n",
    "y_pred = y_pred.flatten()\n",
    "Y_valid = Y_valid.to_numpy().flatten()\n",
    "\n",
    "# MSE\n",
    "mse = MeanSquaredError()\n",
    "mse.update_state(Y_valid, y_pred)\n",
    "mse_result = mse.result().numpy()\n",
    "\n",
    "# RMSE\n",
    "rmse_result = np.sqrt(mse_result)\n",
    "\n",
    "# MAE\n",
    "mae = MeanAbsoluteError()\n",
    "mae.update_state(Y_valid, y_pred)\n",
    "mae_result = mae.result().numpy()\n",
    "\n",
    "# SMAPE (Symmetric Mean Absolute Percentage Error)\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
    "\n",
    "smape_result = smape(Y_valid, y_pred)\n",
    "\n",
    "# R² (R Squared)\n",
    "r2_result = r2_score(Y_valid, y_pred)\n",
    "\n",
    "print(f'MSE: {mse_result}')\n",
    "print(f'RMSE: {rmse_result}')\n",
    "print(f'MAE: {mae_result}')\n",
    "print(f'SMAPE: {smape_result}')\n",
    "print(f'R²: {r2_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 1s 7ms/step\n",
      "MSE: 0.014893919229507446\n",
      "RMSE: 0.12204064428806305\n",
      "MAE: 0.08466027677059174\n",
      "SMAPE: 49.84999332261666\n",
      "R²: 0.4402434736253543\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "# y_pred와 Y_test를 1차원으로 변환\n",
    "y_pred = y_pred.flatten()\n",
    "Y_test = Y_test.to_numpy().flatten()\n",
    "\n",
    "# MSE\n",
    "mse = MeanSquaredError()\n",
    "mse.update_state(Y_test, y_pred)\n",
    "mse_result = mse.result().numpy()\n",
    "\n",
    "# RMSE\n",
    "rmse_result = np.sqrt(mse_result)\n",
    "\n",
    "# MAE\n",
    "mae = MeanAbsoluteError()\n",
    "mae.update_state(Y_test, y_pred)\n",
    "mae_result = mae.result().numpy()\n",
    "\n",
    "# SMAPE (Symmetric Mean Absolute Percentage Error)\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
    "\n",
    "smape_result = smape(Y_test, y_pred)\n",
    "\n",
    "# R² (R Squared)\n",
    "r2_result = r2_score(Y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse_result}')\n",
    "print(f'RMSE: {rmse_result}')\n",
    "print(f'MAE: {mae_result}')\n",
    "print(f'SMAPE: {smape_result}')\n",
    "print(f'R²: {r2_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]2024-09-15 14:47:52.083781: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 29.11GiB (rounded to 31260672000)requested by op Einsum\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-09-15 14:47:52.083850: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-09-15 14:47:52.083865: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 182, Chunks in use: 182. 45.5KiB allocated for chunks. 45.5KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083876: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 6, Chunks in use: 6. 3.0KiB allocated for chunks. 3.0KiB in use in bin. 3.0KiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083885: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 2.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083895: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083906: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 56, Chunks in use: 56. 226.8KiB allocated for chunks. 226.8KiB in use in bin. 224.0KiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083915: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 1, Chunks in use: 0. 12.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083925: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 9, Chunks in use: 9. 175.5KiB allocated for chunks. 175.5KiB in use in bin. 175.5KiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083934: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 36.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083942: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083951: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 2, Chunks in use: 0. 288.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083959: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 3, Chunks in use: 0. 1.03MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083967: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083976: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 5. 9.64MiB allocated for chunks. 9.64MiB in use in bin. 9.63MiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083985: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 4, Chunks in use: 4. 8.99MiB allocated for chunks. 8.99MiB in use in bin. 8.99MiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.083993: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.084002: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 0. 12.08MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.084013: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 4, Chunks in use: 2. 100.38MiB allocated for chunks. 59.22MiB in use in bin. 58.23MiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.084022: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 39.22MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.084030: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-15 14:47:52.084044: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 4. 647.37MiB allocated for chunks. 647.37MiB in use in bin. 647.37MiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.084054: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 3, Chunks in use: 1. 29.61GiB allocated for chunks. 2.33GiB in use in bin. 2.33GiB client-requested in use in bin.\n",
      "2024-09-15 14:47:52.084063: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 29.11GiB was 256.00MiB, Chunk State: \n",
      "  0%|          | 0/100 [00:10<?, ?it/s]2024-09-15 14:47:52.084082: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 4.57GiB | Requested Size: 14.06MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.33GiB | Requested Size: 2.33GiB | in_use: 1 | bin_num: -1, next:   Size: 161.84MiB | Requested Size: 161.84MiB | in_use: 1 | bin_num: -1\n",
      "2024-09-15 14:47:52.084098: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 22.71GiB | Requested Size: 1.12GiB | in_use: 0 | bin_num: 20, prev:   Size: 161.84MiB | Requested Size: 161.84MiB | in_use: 1 | bin_num: -1\n",
      "2024-09-15 14:47:52.084105: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 32654098432\n",
      "2024-09-15 14:47:52.084113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894000000 of size 1280 next 1\n",
      "2024-09-15 14:47:52.084120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894000500 of size 256 next 2\n",
      "2024-09-15 14:47:52.084128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894000600 of size 256 next 3\n",
      "2024-\n",
      "09-15 14:47:52.084134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894000700 of size 256 next 5\n",
      "2024-09-15 14:47:52.084141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894000800 of size 4096 next 6\n",
      "2024-09-15 14:47:52.084147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894001800 of size 256 next 4\n",
      "2024-09-15 14:47:52.084153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894001900 of size 256 next 7\n",
      "2024-09-15 14:47:52.084159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894001a00 of size 256 next 16\n",
      "2024-09-15 14:47:52.084165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894001b00 of size 256 next 10\n",
      "2024-09-15 14:47:52.084171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894001c00 of size 256 next 15\n",
      "2024-09-15 14:47:52.084177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894001d00 of size 256 next 19\n",
      "2024-09-15 14:47:52.084183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894001e00 of size 256 next 20\n",
      "2024-09-15 14:47:52.084189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894001f00 of size 256 next 21\n",
      "2024-09-15 14:47:52.084195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002000 of size 256 next 22\n",
      "2024-09-15 14:47:52.084201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002100 of size 256 next 23\n",
      "2024-09-15 14:47:52.084207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002200 of size 256 next 24\n",
      "2024-09-15 14:47:52.084213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002300 of size 256 next 25\n",
      "2024-09-15 14:47:52.084219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002400 of size 256 next 26\n",
      "2024-09-15 14:47:52.084225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002500 of size 256 next 30\n",
      "2024-09-15 14:47:52.084231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002600 of size 256 next 28\n",
      "2024-09-15 14:47:52.084237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002700 of size 256 next 29\n",
      "2024-09-15 14:47:52.084243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002800 of size 256 next 27\n",
      "2024-09-15 14:47:52.084249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002900 of size 256 next 8\n",
      "2024-09-15 14:47:52.084255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894002a00 of size 4096 next 9\n",
      "2024-09-15 14:47:52.084261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894003a00 of size 4352 next 11\n",
      "2024-09-15 14:47:52.084267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894004b00 of size 4096 next 12\n",
      "2024-09-15 14:47:52.084273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894005b00 of size 4352 next 13\n",
      "2024-09-15 14:47:52.084279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894006c00 of size 4096 next 14\n",
      "2024-09-15 14:47:52.084285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894007c00 of size 256 next 31\n",
      "2024-09-15 14:47:52.084293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894007d00 of size 256 next 32\n",
      "2024-09-15 14:47:52.084300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894007e00 of size 256 next 103\n",
      "2024-09-15 14:47:52.084305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894007f00 of size 256 next 107\n",
      "2024-09-15 14:47:52.084312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894008000 of size 256 next 108\n",
      "2024-09-15 14:47:52.084318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894008100 of size 256 next 105\n",
      "2024-09-15 14:47:52.084324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894008200 of size 512 next 106\n",
      "2024-09-15 14:47:52.084330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894008400 of size 256 next 110\n",
      "2024-09-15 14:47:52.084336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894008500 of size 256 next 111\n",
      "2024-09-15 14:47:52.084343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894008600 of size 5632 next 18\n",
      "2024-09-15 14:47:52.084349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894009c00 of size 4096 next 17\n",
      "2024-09-15 14:47:52.084355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889400ac00 of size 4352 next 36\n",
      "2024-09-15 14:47:52.084361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889400bd00 of size 4096 next 37\n",
      "2024-09-15 14:47:52.084367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889400cd00 of size 4352 next 38\n",
      "2024-09-15 14:47:52.084373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889400de00 of size 4096 next 39\n",
      "2024-09-15 14:47:52.084379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889400ee00 of size 4352 next 40\n",
      "2024-09-15 14:47:52.084385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889400ff00 of size 4096 next 41\n",
      "2024-09-15 14:47:52.084391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894010f00 of size 256 next 33\n",
      "2024-09-15 14:47:52.084397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011000 of size 256 next 34\n",
      "2024-09-15 14:47:52.084403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011100 of size 256 next 35\n",
      "2024-09-15 14:47:52.084409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011200 of size 256 next 44\n",
      "2024-09-15 14:47:52.084416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011300 of size 256 next 45\n",
      "2024-09-15 14:47:52.084421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011400 of size 256 next 47\n",
      "2024-09-15 14:47:52.084427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011500 of size 256 next 46\n",
      "2024-09-15 14:47:52.084433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011600 of size 256 next 48\n",
      "2024-09-15 14:47:52.084440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011700 of size 256 next 49\n",
      "2024-09-15 14:47:52.084446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011800 of size 256 next 50\n",
      "2024-09-15 14:47:52.084452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011900 of size 256 next 51\n",
      "2024-09-15 14:47:52.084458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011a00 of size 256 next 52\n",
      "2024-09-15 14:47:52.084464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011b00 of size 256 next 53\n",
      "2024-09-15 14:47:52.084470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011c00 of size 256 next 54\n",
      "2024-09-15 14:47:52.084476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011d00 of size 256 next 55\n",
      "2024-09-15 14:47:52.084482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011e00 of size 256 next 64\n",
      "2024-09-15 14:47:52.084488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894011f00 of size 256 next 42\n",
      "2024-09-15 14:47:52.084494: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894012000 of size 4096 next 43\n",
      "2024-09-15 14:47:52.084502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894013000 of size 4096 next 57\n",
      "2024-09-15 14:47:52.084508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894014000 of size 4096 next 56\n",
      "2024-09-15 14:47:52.084514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894015000 of size 4096 next 59\n",
      "2024-09-15 14:47:52.084520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894016000 of size 4096 next 58\n",
      "2024-09-15 14:47:52.084526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894017000 of size 4096 next 61\n",
      "2024-09-15 14:47:52.084532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894018000 of size 4096 next 60\n",
      "2024-09-15 14:47:52.084539: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019000 of size 256 next 65\n",
      "2024-09-15 14:47:52.084545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019100 of size 256 next 67\n",
      "2024-09-15 14:47:52.084551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019200 of size 256 next 66\n",
      "2024-09-15 14:47:52.084557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019300 of size 256 next 68\n",
      "2024-09-15 14:47:52.084563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019400 of size 256 next 69\n",
      "2024-09-15 14:47:52.084569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019500 of size 256 next 70\n",
      "2024-09-15 14:47:52.084575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019600 of size 256 next 71\n",
      "2024-09-15 14:47:52.084581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019700 of size 256 next 72\n",
      "2024-09-15 14:47:52.084587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019800 of size 256 next 73\n",
      "2024-09-15 14:47:52.084593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019900 of size 256 next 74\n",
      "2024-09-15 14:47:52.084599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019a00 of size 256 next 75\n",
      "2024-09-15 14:47:52.084605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019b00 of size 256 next 84\n",
      "2024-09-15 14:47:52.084611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019c00 of size 256 next 85\n",
      "2024-09-15 14:47:52.084617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019d00 of size 256 next 86\n",
      "2024-09-15 14:47:52.084623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019e00 of size 256 next 87\n",
      "2024-09-15 14:47:52.084630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894019f00 of size 256 next 63\n",
      "2024-09-15 14:47:52.084636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889401a000 of size 4096 next 62\n",
      "2024-09-15 14:47:52.084642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889401b000 of size 4096 next 77\n",
      "2024-09-15 14:47:52.084648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889401c000 of size 4096 next 76\n",
      "2024-09-15 14:47:52.084654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889401d000 of size 4096 next 79\n",
      "2024-09-15 14:47:52.084660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889401e000 of size 4096 next 78\n",
      "2024-09-15 14:47:52.084666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889401f000 of size 4096 next 81\n",
      "2024-09-15 14:47:52.084672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894020000 of size 4096 next 80\n",
      "2024-09-15 14:47:52.084679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021000 of size 256 next 88\n",
      "2024-09-15 14:47:52.084685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021100 of size 256 next 89\n",
      "2024-09-15 14:47:52.084691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021200 of size 256 next 90\n",
      "2024-09-15 14:47:52.084697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021300 of size 256 next 91\n",
      "2024-09-15 14:47:52.084703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021400 of size 256 next 92\n",
      "2024-09-15 14:47:52.084710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021500 of size 256 next 93\n",
      "2024-09-15 14:47:52.084716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021600 of size 256 next 94\n",
      "2024-09-15 14:47:52.084722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021700 of size 256 next 95\n",
      "2024-09-15 14:47:52.084728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021800 of size 256 next 96\n",
      "2024-09-15 14:47:52.084734: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021900 of size 512 next 99\n",
      "2024-09-15 14:47:52.084740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021b00 of size 256 next 97\n",
      "2024-09-15 14:47:52.084746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021c00 of size 256 next 98\n",
      "2024-09-15 14:47:52.084753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021d00 of size 256 next 104\n",
      "2024-09-15 14:47:52.084759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021e00 of size 256 next 102\n",
      "2024-09-15 14:47:52.084765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894021f00 of size 256 next 83\n",
      "2024-09-15 14:47:52.084771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894022000 of size 4096 next 82\n",
      "2024-09-15 14:47:52.084777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8894023000 of size 36864 next 101\n",
      "2024-09-15 14:47:52.084784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889402c000 of size 18432 next 100\n",
      "2024-09-15 14:47:52.084790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8894030800 of size 147456 next 303\n",
      "2024-09-15 14:47:52.084796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894054800 of size 20736 next 252\n",
      "2024-09-15 14:47:52.084802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894059900 of size 20736 next 239\n",
      "2024-09-15 14:47:52.084808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889405ea00 of size 20736 next 284\n",
      "2024-09-15 14:47:52.084814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8894063b00 of size 380160 next 292\n",
      "2024-09-15 14:47:52.084820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f88940c0800 of size 20736 next 315\n",
      "2024-09-15 14:47:52.084827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f88940c5900 of size 147456 next 264\n",
      "2024-09-15 14:47:52.084833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f88940e9900 of size 20736 next 332\n",
      "2024-09-15 14:47:52.084839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f88940eea00 of size 20736 next 263\n",
      "2024-09-15 14:47:52.084844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f88940f3b00 of size 379136 next 109\n",
      "2024-09-15 14:47:52.084851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894150400 of size 4096 next 112\n",
      "2024-09-15 14:47:52.084857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894151400 of size 4096 next 113\n",
      "2024-09-15 14:47:52.084863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894152400 of size 4096 next 114\n",
      "2024-09-15 14:47:52.084869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894153400 of size 4096 next 115\n",
      "2024-09-15 14:47:52.084875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894154400 of size 4096 next 116\n",
      "2024-09-15 14:47:52.084881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894155400 of size 4096 next 117\n",
      "2024-09-15 14:47:52.084887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894156400 of size 4096 next 118\n",
      "2024-09-15 14:47:52.084893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894157400 of size 4096 next 119\n",
      "2024-09-15 14:47:52.084899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894158400 of size 4096 next 120\n",
      "2024-09-15 14:47:52.084905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894159400 of size 4096 next 121\n",
      "2024-09-15 14:47:52.084913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889415a400 of size 4096 next 122\n",
      "2024-09-15 14:47:52.084919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889415b400 of size 4096 next 123\n",
      "2024-09-15 14:47:52.084925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889415c400 of size 4096 next 124\n",
      "2024-09-15 14:47:52.084931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889415d400 of size 256 next 125\n",
      "2024-09-15 14:47:52.084937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889415d500 of size 256 next 126\n",
      "2024-09-15 14:47:52.084943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889415d600 of size 4096 next 127\n",
      "2024-09-15 14:47:52.084949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889415e600 of size 4096 next 128\n",
      "2024-09-15 14:47:52.084955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889415f600 of size 4096 next 129\n",
      "2024-09-15 14:47:52.084961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894160600 of size 4096 next 130\n",
      "2024-09-15 14:47:52.084967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894161600 of size 4096 next 131\n",
      "2024-09-15 14:47:52.084973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894162600 of size 4096 next 132\n",
      "2024-09-15 14:47:52.084979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894163600 of size 4096 next 133\n",
      "2024-09-15 14:47:52.084985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894164600 of size 4096 next 134\n",
      "2024-09-15 14:47:52.084991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894165600 of size 4096 next 135\n",
      "2024-09-15 14:47:52.084997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894166600 of size 4096 next 136\n",
      "2024-09-15 14:47:52.085003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894167600 of size 4096 next 137\n",
      "2024-09-15 14:47:52.085009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894168600 of size 4096 next 138\n",
      "2024-09-15 14:47:52.085016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894169600 of size 4096 next 139\n",
      "2024-09-15 14:47:52.085022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416a600 of size 4096 next 140\n",
      "2024-09-15 14:47:52.085028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416b600 of size 256 next 141\n",
      "2024-09-15 14:47:52.085034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416b700 of size 256 next 142\n",
      "2024-09-15 14:47:52.085040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416b800 of size 256 next 143\n",
      "2024-09-15 14:47:52.085046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416b900 of size 256 next 144\n",
      "2024-09-15 14:47:52.085052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416ba00 of size 256 next 145\n",
      "2024-09-15 14:47:52.085058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416bb00 of size 256 next 146\n",
      "2024-09-15 14:47:52.085064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416bc00 of size 256 next 147\n",
      "2024-09-15 14:47:52.085070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416bd00 of size 256 next 148\n",
      "2024-09-15 14:47:52.085076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416be00 of size 256 next 149\n",
      "2024-09-15 14:47:52.085082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416bf00 of size 256 next 150\n",
      "2024-09-15 14:47:52.085088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c000 of size 256 next 151\n",
      "2024-09-15 14:47:52.085094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c100 of size 256 next 152\n",
      "2024-09-15 14:47:52.085100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c200 of size 256 next 153\n",
      "2024-09-15 14:47:52.085106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c300 of size 256 next 154\n",
      "2024-09-15 14:47:52.085114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c400 of size 256 next 155\n",
      "2024-09-15 14:47:52.085120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c500 of size 256 next 156\n",
      "2024-09-15 14:47:52.085126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c600 of size 256 next 157\n",
      "2024-09-15 14:47:52.085132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c700 of size 256 next 158\n",
      "2024-09-15 14:47:52.085138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c800 of size 256 next 159\n",
      "2024-09-15 14:47:52.085144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416c900 of size 256 next 160\n",
      "2024-09-15 14:47:52.085150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416ca00 of size 256 next 161\n",
      "2024-09-15 14:47:52.085156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416cb00 of size 256 next 162\n",
      "2024-09-15 14:47:52.085162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416cc00 of size 256 next 163\n",
      "2024-09-15 14:47:52.085168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416cd00 of size 256 next 164\n",
      "2024-09-15 14:47:52.085174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416ce00 of size 256 next 165\n",
      "2024-09-15 14:47:52.085180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416cf00 of size 256 next 166\n",
      "2024-09-15 14:47:52.085186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d000 of size 256 next 167\n",
      "2024-09-15 14:47:52.085192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d100 of size 256 next 168\n",
      "2024-09-15 14:47:52.085198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d200 of size 256 next 169\n",
      "2024-09-15 14:47:52.085204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d300 of size 256 next 170\n",
      "2024-09-15 14:47:52.085210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d400 of size 256 next 171\n",
      "2024-09-15 14:47:52.085216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d500 of size 256 next 172\n",
      "2024-09-15 14:47:52.085222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d600 of size 256 next 173\n",
      "2024-09-15 14:47:52.085228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d700 of size 256 next 174\n",
      "2024-09-15 14:47:52.085234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d800 of size 256 next 175\n",
      "2024-09-15 14:47:52.085241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416d900 of size 256 next 176\n",
      "2024-09-15 14:47:52.085246: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416da00 of size 256 next 177\n",
      "2024-09-15 14:47:52.085252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416db00 of size 256 next 178\n",
      "2024-09-15 14:47:52.085258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416dc00 of size 256 next 179\n",
      "2024-09-15 14:47:52.085264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416dd00 of size 256 next 180\n",
      "2024-09-15 14:47:52.085270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416de00 of size 256 next 181\n",
      "2024-09-15 14:47:52.085276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416df00 of size 256 next 182\n",
      "2024-09-15 14:47:52.085282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e000 of size 256 next 183\n",
      "2024-09-15 14:47:52.085288: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e100 of size 256 next 184\n",
      "2024-09-15 14:47:52.085294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e200 of size 256 next 185\n",
      "2024-09-15 14:47:52.085300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e300 of size 256 next 186\n",
      "2024-09-15 14:47:52.085306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e400 of size 256 next 187\n",
      "2024-09-15 14:47:52.085314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e500 of size 256 next 188\n",
      "2024-09-15 14:47:52.085320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e600 of size 256 next 189\n",
      "2024-09-15 14:47:52.085326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e700 of size 256 next 190\n",
      "2024-09-15 14:47:52.085332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889416e800 of size 18432 next 191\n",
      "2024-09-15 14:47:52.085338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894173000 of size 18432 next 192\n",
      "2024-09-15 14:47:52.085344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894177800 of size 512 next 193\n",
      "2024-09-15 14:47:52.085350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894177a00 of size 512 next 194\n",
      "2024-09-15 14:47:52.085356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894177c00 of size 512 next 195\n",
      "2024-09-15 14:47:52.085363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894177e00 of size 512 next 196\n",
      "2024-09-15 14:47:52.085369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178000 of size 256 next 197\n",
      "2024-09-15 14:47:52.085375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178100 of size 256 next 198\n",
      "2024-09-15 14:47:52.085381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178200 of size 256 next 199\n",
      "2024-09-15 14:47:52.085387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178300 of size 256 next 200\n",
      "2024-09-15 14:47:52.085393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178400 of size 256 next 201\n",
      "2024-09-15 14:47:52.085399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178500 of size 256 next 202\n",
      "2024-09-15 14:47:52.085405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178600 of size 256 next 203\n",
      "2024-09-15 14:47:52.085422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178700 of size 256 next 204\n",
      "2024-09-15 14:47:52.085429: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178800 of size 256 next 205\n",
      "2024-09-15 14:47:52.085435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178900 of size 256 next 206\n",
      "2024-09-15 14:47:52.085441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178a00 of size 256 next 207\n",
      "2024-09-15 14:47:52.085447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178b00 of size 256 next 208\n",
      "2024-09-15 14:47:52.085453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178c00 of size 256 next 209\n",
      "2024-09-15 14:47:52.085459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178d00 of size 256 next 210\n",
      "2024-09-15 14:47:52.085465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178e00 of size 256 next 211\n",
      "2024-09-15 14:47:52.085471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894178f00 of size 256 next 212\n",
      "2024-09-15 14:47:52.085477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179000 of size 256 next 213\n",
      "2024-09-15 14:47:52.085483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179100 of size 256 next 214\n",
      "2024-09-15 14:47:52.085489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179200 of size 256 next 215\n",
      "2024-09-15 14:47:52.085495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179300 of size 256 next 216\n",
      "2024-09-15 14:47:52.085501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179400 of size 256 next 217\n",
      "2024-09-15 14:47:52.085507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179500 of size 256 next 218\n",
      "2024-09-15 14:47:52.085513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179600 of size 256 next 219\n",
      "2024-09-15 14:47:52.085519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179700 of size 256 next 220\n",
      "2024-09-15 14:47:52.085527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179800 of size 256 next 307\n",
      "2024-09-15 14:47:52.085533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179900 of size 256 next 321\n",
      "2024-09-15 14:47:52.085538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179a00 of size 256 next 275\n",
      "2024-09-15 14:47:52.085544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179b00 of size 256 next 299\n",
      "2024-09-15 14:47:52.085550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179c00 of size 256 next 227\n",
      "2024-09-15 14:47:52.085557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179d00 of size 256 next 267\n",
      "2024-09-15 14:47:52.085563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179e00 of size 256 next 331\n",
      "2024-09-15 14:47:52.085569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894179f00 of size 256 next 254\n",
      "2024-09-15 14:47:52.085575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a000 of size 256 next 277\n",
      "2024-09-15 14:47:52.085581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a100 of size 256 next 224\n",
      "2024-09-15 14:47:52.085587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a200 of size 256 next 328\n",
      "2024-09-15 14:47:52.085593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a300 of size 256 next 336\n",
      "2024-09-15 14:47:52.085599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a400 of size 256 next 278\n",
      "2024-09-15 14:47:52.085605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a500 of size 256 next 262\n",
      "2024-09-15 14:47:52.085611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a600 of size 256 next 314\n",
      "2024-09-15 14:47:52.085617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a700 of size 256 next 477\n",
      "2024-09-15 14:47:52.085623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a800 of size 256 next 269\n",
      "2024-09-15 14:47:52.085629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417a900 of size 256 next 221\n",
      "2024-09-15 14:47:52.085635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417aa00 of size 256 next 222\n",
      "2024-09-15 14:47:52.085642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f889417ab00 of size 1815552 next 310\n",
      "2024-09-15 14:47:52.085648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894335f00 of size 256 next 478\n",
      "2024-09-15 14:47:52.085654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894336000 of size 256 next 274\n",
      "2024-09-15 14:47:52.085660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8894336100 of size 1024 next 335\n",
      "2024-09-15 14:47:52.085666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894336500 of size 256 next 285\n",
      "2024-09-15 14:47:52.085672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894336600 of size 256 next 236\n",
      "2024-09-15 14:47:52.085678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894336700 of size 256 next 271\n",
      "2024-09-15 14:47:52.085684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8894336800 of size 12544 next 251\n",
      "2024-09-15 14:47:52.085690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894339900 of size 256 next 288\n",
      "2024-09-15 14:47:52.085696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8894339a00 of size 319488 next 327\n",
      "2024-09-15 14:47:52.085702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894387a00 of size 256 next 266\n",
      "2024-09-15 14:47:52.085708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894387b00 of size 256 next 258\n",
      "2024-09-15 14:47:52.085714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894387c00 of size 256 next 249\n",
      "2024-09-15 14:47:52.085720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894387d00 of size 256 next 325\n",
      "2024-09-15 14:47:52.085728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894387e00 of size 256 next 261\n",
      "2024-09-15 14:47:52.085735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894387f00 of size 2356992 next 323\n",
      "2024-09-15 14:47:52.085742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f88945c7600 of size 2356992 next 305\n",
      "2024-09-15 14:47:52.085748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894806d00 of size 2356992 next 295\n",
      "2024-09-15 14:47:52.085755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8894a46400 of size 2498411520 next 226\n",
      "2024-09-15 14:47:52.085761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f89298f2000 of size 4911971328 next 313\n",
      "2024-09-15 14:47:52.085768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a4e55dc00 of size 169703424 next 484\n",
      "2024-09-15 14:47:52.085774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a58735400 of size 2356992 next 242\n",
      "2024-09-15 14:47:52.085780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8a58974b00 of size 16819200 next 248\n",
      "2024-09-15 14:47:52.085787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a5997ef00 of size 2073600 next 326\n",
      "2024-09-15 14:47:52.085793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a59b79300 of size 30528000 next 489\n",
      "2024-09-15 14:47:52.085799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8a5b896500 of size 41126400 next 223\n",
      "2024-09-15 14:47:52.085805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a5dfcef00 of size 2073600 next 232\n",
      "2024-09-15 14:47:52.085812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a5e1c9300 of size 31564800 next 297\n",
      "2024-09-15 14:47:52.085818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a5ffe3700 of size 2073600 next 243\n",
      "2024-09-15 14:47:52.085824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8a601ddb00 of size 12672000 next 304\n",
      "2024-09-15 14:47:52.085830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a60df3700 of size 2073600 next 311\n",
      "2024-09-15 14:47:52.085837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8a60fedb00 of size 26341632 next 298\n",
      "2024-09-15 14:47:52.085843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a6290cc00 of size 169703424 next 281\n",
      "2024-09-15 14:47:52.085849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a6cae4400 of size 169703424 next 287\n",
      "2024-09-15 14:47:52.085855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8a76cbbc00 of size 169703424 next 247\n",
      "2024-09-15 14:47:52.085861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8a80e93400 of size 24384424960 next 18446744073709551615\n",
      "2024-09-15 14:47:52.085867: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-09-15 14:47:52.085876: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 182 Chunks of size 256 totalling 45.5KiB\n",
      "2024-09-15 14:47:52.085884: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 512 totalling 3.0KiB\n",
      "2024-09-15 14:47:52.085891: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-09-15 14:47:52.085899: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 50 Chunks of size 4096 totalling 200.0KiB\n",
      "2024-09-15 14:47:52.085906: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 4352 totalling 21.2KiB\n",
      "2024-09-15 14:47:52.085913: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5632 totalling 5.5KiB\n",
      "2024-09-15 14:47:52.085921: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 18432 totalling 54.0KiB\n",
      "2024-09-15 14:47:52.085928: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 20736 totalling 121.5KiB\n",
      "2024-09-15 14:47:52.085935: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1815552 totalling 1.73MiB\n",
      "2024-09-15 14:47:52.085942: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 2073600 totalling 7.91MiB\n",
      "2024-09-15 14:47:52.085951: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 2356992 totalling 8.99MiB\n",
      "2024-09-15 14:47:52.085958: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 30528000 totalling 29.11MiB\n",
      "2024-09-15 14:47:52.085966: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 31564800 totalling 30.10MiB\n",
      "2024-09-15 14:47:52.085973: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 169703424 totalling 647.37MiB\n",
      "2024-09-15 14:47:52.085981: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2498411520 totalling 2.33GiB\n",
      "2024-09-15 14:47:52.085987: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 3.04GiB\n",
      "2024-09-15 14:47:52.085995: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 32654098432 memory_limit_: 32654098432 available bytes: 0 curr_region_allocation_bytes_: 65308196864\n",
      "2024-09-15 14:47:52.086006: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     32654098432\n",
      "InUse:                      3259318784\n",
      "MaxInUse:                   9309914880\n",
      "NumAllocs:                     5051174\n",
      "MaxAllocSize:               2498411520\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-09-15 14:47:52.086032: W tensorflow/tsl/framework/bfc_allocator.cc:497] ********______________****__________________________________________________________________________\n",
      "2024-09-15 14:47:52.086057: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at einsum_op_impl.h:529 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[7632000,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'query' (type EinsumDense).\n\n{{function_node __wrapped__Einsum_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[7632000,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Einsum] name: \n\nCall arguments received by layer 'query' (type EinsumDense):\n  • inputs=tf.Tensor(shape=(212000, 36, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mKernelExplainer(model, X_train_background)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# SHAP 값 계산\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Summary plot\u001b[39;00m\n\u001b[1;32m     20\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_train_sample)\n",
      "File \u001b[0;32m~/anaconda3/envs/jw_tensorflow/lib/python3.11/site-packages/shap/explainers/_kernel.py:271\u001b[0m, in \u001b[0;36mKernelExplainer.shap_values\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[1;32m    270\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[0;32m--> 271\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    273\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/anaconda3/envs/jw_tensorflow/lib/python3.11/site-packages/shap/explainers/_kernel.py:476\u001b[0m, in \u001b[0;36mKernelExplainer.explain\u001b[0;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernelWeights[nfixed_samples:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m weight_left \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernelWeights[nfixed_samples:]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# execute the model on the synthetic samples we have created\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;66;03m# solve then expand the feature importance (Shapley value) vector to contain the non-varying features\u001b[39;00m\n\u001b[1;32m    479\u001b[0m phi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgroups_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD))\n",
      "File \u001b[0;32m~/anaconda3/envs/jw_tensorflow/lib/python3.11/site-packages/shap/explainers/_kernel.py:615\u001b[0m, in \u001b[0;36mKernelExplainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index_ordered:\n\u001b[1;32m    614\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m--> 615\u001b[0m modelOut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modelOut, (pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mSeries)):\n\u001b[1;32m    617\u001b[0m     modelOut \u001b[38;5;241m=\u001b[39m modelOut\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/anaconda3/envs/jw_tensorflow/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/jw_tensorflow/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5887\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5888\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'query' (type EinsumDense).\n\n{{function_node __wrapped__Einsum_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[7632000,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Einsum] name: \n\nCall arguments received by layer 'query' (type EinsumDense):\n  • inputs=tf.Tensor(shape=(212000, 36, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 샘플링할 비율 또는 샘플 수 설정\n",
    "sample_size = 100  # 예를 들어 100개의 샘플을 사용\n",
    "\n",
    "# 배경 데이터 샘플링\n",
    "X_train_background = X_train_np[np.random.choice(X_train_np.shape[0], sample_size, replace=False)]\n",
    "\n",
    "# 예측 데이터 샘플링\n",
    "X_train_sample = X_train_np[np.random.choice(X_train_np.shape[0], sample_size, replace=False)]\n",
    "\n",
    "# SHAP explainer 객체 생성\n",
    "explainer = shap.KernelExplainer(model, X_train_background)\n",
    "\n",
    "# SHAP 값 계산\n",
    "shap_values = explainer.shap_values(X_train_sample)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X_train_sample)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jw_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
